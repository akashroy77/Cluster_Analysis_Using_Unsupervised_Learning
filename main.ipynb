{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iiXSa1QOeJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D,Flatten, Reshape\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as k\n",
        "from sklearn.mixture import GaussianMixture as GMM\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import mode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M34nOHHOvXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loads the training and test data sets from Keras\n",
        "(images_train, labels_train), (images_test, labels_test) = fashion_mnist.load_data()\n",
        "images_train=images_train.reshape(images_train.shape[0],images_train.shape[1]*images_train.shape[2])\n",
        "images_test=images_test.reshape(images_test.shape[0],images_test.shape[1]*images_test.shape[2])\n",
        "\n",
        "#Normalizing the Data by dividing the data by 255 (Maximum value of a pixel)\n",
        "images_train = images_train.astype('float32') / 255\n",
        "images_test = images_test.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7C7R7fG5oHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initializing KMeans object and Using Kmeans for Clustering\n",
        "kmeans = KMeans(n_clusters=10,max_iter=500)\n",
        "kmeans.fit(images_train)\n",
        "y_pred_test=kmeans.predict(images_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7FX4XJV58j-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating Confustion Matrix and Heat Map\n",
        "cm=confusion_matrix(labels_test,y_pred_test)\n",
        "j=0\n",
        "print(cm)\n",
        "plt.figure(figsize=(8,8))\n",
        "#Aligning Confusion MAtrix \n",
        "for i in range(10):\n",
        "    maximum=np.max(cm[i])\n",
        "    s=np.where(cm==maximum)\n",
        "    cm[s[0],s[1]]=cm[i,j]\n",
        "    cm[i,j]=maximum\n",
        "    j=j+1\n",
        "sns.heatmap(cm, annot=True,square=True,fmt=\"d\",cbar=False, center=0,linewidth=1,cmap=\"Blues\", xticklabels=np.unique(labels_train), yticklabels=np.unique(labels_train))\n",
        "print(cm)\n",
        "plt.xlabel('true Label')\n",
        "plt.ylabel('predicted Label')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "501fdiYYEIhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculating Accuracy Score\n",
        "accuracy_score_P1=metrics.normalized_mutual_info_score(labels_test,y_pred_test)\n",
        "print(accuracy_score_P1*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvQe73UoOwIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocessing Testing data for Auto Encoder\n",
        "images_train_cnn = images_train.reshape((len(images_train), 28, 28, 1))\n",
        "\n",
        "#Preprocessing Testing data for Auto Encoder\n",
        "images_test_cnn= images_test.reshape((len(images_test), 28, 28, 1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xcw41XnOyV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Building the Auto-Encoder Model using a CNN\n",
        "autoencoder = Sequential()\n",
        "\n",
        "# Encoder Layer\n",
        "autoencoder.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=images_train_cnn.shape[1:]))\n",
        "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
        "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
        "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
        "autoencoder.add(Conv2D(8, (3, 3), strides=(2,2), activation='relu', padding='same'))\n",
        "\n",
        "# Flatten Intermediate Part\n",
        "autoencoder.add(Flatten())\n",
        "autoencoder.add(Reshape((4, 4, 8)))\n",
        "\n",
        "# Decoder Layer\n",
        "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
        "autoencoder.add(UpSampling2D((2, 2)))\n",
        "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
        "autoencoder.add(UpSampling2D((2, 2)))\n",
        "autoencoder.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "autoencoder.add(UpSampling2D((2, 2)))\n",
        "autoencoder.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
        "\n",
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PzH1zv-OyZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Only Encoder Part so we can use this part for encoding the Training and Test Dataset before sending it to K-means clustering\n",
        "only_encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('flatten_1').output)\n",
        "only_encoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_yIhO5rO37a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compiling and Training the Encoder Model\n",
        "autoencoder.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
        "history=autoencoder.fit(images_train_cnn, images_train_cnn,epochs=25,validation_split=0.1,batch_size=500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNwzOaeqRVeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Enocoding the Training and Test Data Set using only encoder part of the model\n",
        "encoded_train_data = only_encoder.predict(images_train_cnn)\n",
        "encoded_test_data = only_encoder.predict(images_test_cnn)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ1lROQ_O3-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using K-means for clusturing the Encoded Images and then calculating the accuracy\n",
        "kmeans = KMeans(n_clusters=10)\n",
        "y_pred_train_cnn=kmeans.fit(encoded_train_data)\n",
        "y_pred_test_P2=kmeans.predict(encoded_test_data)\n",
        "training_score=metrics.normalized_mutual_info_score(labels_test,y_pred_test_P2)\n",
        "print(training_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-cwDBNJXcQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating Confustion Matrix and Heat Map for Auto Encoder with K-means Clustering\n",
        "cm_k=confusion_matrix(labels_test,y_pred_test_P2)\n",
        "j=0\n",
        "print(cm_k)\n",
        "plt.figure(figsize=(8,8))\n",
        "#Aligning Confusion MAtrix \n",
        "for i in range(10):\n",
        "    maximum=np.max(cm_k[i])\n",
        "    s=np.where(cm_k==maximum)\n",
        "    cm_k[s[0],s[1]]=cm_k[i,j]\n",
        "    cm_k[i,j]=maximum\n",
        "    j=j+1\n",
        "sns.heatmap(cm, annot=True,square=True,fmt=\"d\",cbar=False, center=0,linewidth=1,cmap=\"Blues\", xticklabels=np.unique(labels_train), yticklabels=np.unique(labels_train))\n",
        "print(cm_k)\n",
        "plt.xlabel('true Label')\n",
        "plt.ylabel('predicted Label')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d21mIXT6d6vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plotting graph of training loss and validation loss vs number of epochs while training for autoencoder\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ygILxYIcmfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using Gaussian Mixture Model for clusturing the Encoded Images and then calculating the accuracy\n",
        "gmm=GMM(n_components=10).fit(encoded_train_data)\n",
        "y_pred_test_P3=gmm.predict(encoded_test_data)\n",
        "training_score_gmm=metrics.normalized_mutual_info_score(labels_test,gmm_predict)\n",
        "print(training_score_gmm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5Xg0Ifxe_cA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taQFsSqktyTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating Confustion Matrix and Heat Map for Auto Encoder with Gaussian Mixture Model\n",
        "cm_GMM=confusion_matrix(labels_test,y_pred_test_P3)\n",
        "j=0\n",
        "print(cm_GMM)\n",
        "plt.figure(figsize=(8,8))\n",
        "#Aligning Confusion MAtrix with Cluster Ids\n",
        "for i in range(10):\n",
        "    maximum=np.max(cm_GMM[i])\n",
        "    s=np.where(cm_GMM==maximum)\n",
        "    cm_GMM[s[0],s[1]]=cm_GMM[i,j]\n",
        "    cm_GMM[i,j]=maximum\n",
        "    j=j+1\n",
        "sns.heatmap(cm, annot=True,square=True,fmt=\"d\",cbar=False, center=0,linewidth=1,cmap=\"Blues\", xticklabels=np.unique(labels_train), yticklabels=np.unique(labels_train))\n",
        "print(cm_GMM)\n",
        "plt.xlabel('true Label')\n",
        "plt.ylabel('predicted Label')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2V2aRINfZqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}